{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb594ab",
   "metadata": {},
   "source": [
    "# 🚀 Mastering Prompt Engineering with LangChain\n",
    "\n",
    "Hello everyone! this notebook is a complete guide to what is Prompt Engineering, types of prompts with clear definitions & examples along with crafting prompt templates with LangChain.\n",
    "\n",
    "Note - **Includes my touch of crafting prompts examples & templates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b3821",
   "metadata": {},
   "source": [
    "## What exactly if Prompt Engineering?\n",
    "\n",
    "- Prompt Engineering is a technique to design/craft effective user inputs (\"Prompts\" - text based instructions) that guide SOTA LLMs like GPT, Gemini, Co-piolet etc, to give accurate, useful and controlled outputs.\n",
    "\n",
    "- This technology/Domain of Data Science is very crucial in building LLM powered AI applications, producing instruction & reasoning based large language models.\n",
    "\n",
    "### Types of Prompt Techniques\n",
    "\n",
    "#### 🔹 Zero-Shot Prompting\n",
    "**Definition**: In this we ask the model to perform a specific task with no prior examples.\n",
    "\n",
    "**Example**:\n",
    "```text\n",
    "Prompt: \"Translate the sentence into Telugu: I am learning AI.\"\n",
    "Output: \"నేను ఏఐ నేర్చుకు౦టున్నాను.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b59df",
   "metadata": {},
   "source": [
    "#### 🔹 One-Shot Prompting\n",
    "**Definition**: This technique provides the LLM with one example to guide the model’s behavior.\n",
    "\n",
    "**Example**:\n",
    "```text\n",
    "Prompt: \"Learn the example below and translate the given sentence into Telugu\"\n",
    "Example:\n",
    "Telugu: Hello\n",
    "French: హలో \n",
    "\n",
    "Now translate:\n",
    "English: Good night\n",
    "Telugu: గుడ్ నైట్ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4d28b",
   "metadata": {},
   "source": [
    "#### 🔹 Few-Shot Prompting\n",
    "**Definition**: This technique provides few labeled examples to help the model understand the task and perform the same.\n",
    "\n",
    "**Example**:\n",
    "```text\n",
    "Q: Who is the former captain of Indian worldcup team?\n",
    "A: Rohit Sharma\n",
    "Q: Who is the former captain of England worldcup team?\n",
    "A: Ben Stokes\n",
    "Q: Who is the former captain of Australian worldcup team?\n",
    "A:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bf7fd",
   "metadata": {},
   "source": [
    "#### 🔹 Chain-of-Thought (CoT) Prompting\n",
    "**Definition**: This technique often adds example text phrases like \"Let's think step-by-step (followed by example break-down) which encourages the model to reason & understand the task clearly.\n",
    "\n",
    "**Example**:\n",
    "```text\n",
    "Q: If you have 3 red caps and add 2 more, how many do you have?\n",
    "A: Let's think step-by-step.\n",
    "First, you have 3 red caps. Then you get 2 more red caps.\n",
    "Total: 5 red caps.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b6c2d",
   "metadata": {},
   "source": [
    "#### 🔹 ReAct Prompting\n",
    "**Definition**: This technique is also known as \"Reason first the  Act\" which combines reasoning with actions (tool usage) for langchain agents.\n",
    "\n",
    "**Example**:\n",
    "```text\n",
    "Thought/Reason: I need to find the current time.\n",
    "Action: Use appropriate tool (Clock API)\n",
    "Observation: The time is 4:30 PM\n",
    "Answer: The current time is 4:30 PM.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495f476",
   "metadata": {},
   "source": [
    "#### 🔹 Self-Ask Prompting\n",
    "**Definition**: This technique allows the LLM to ask for clarifying sub-questions to better understand the task at hand and then answer the main question.\n",
    "\n",
    "**Example**:\n",
    "```text\n",
    "Q: What is the age of Indian prime minister?\n",
    "Follow-up: Who is Indian prime minister? Narendra Modi\n",
    "Follow-up: When was he born? 1950\n",
    "Answer: Narendra modi was born in 1950\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f32d5",
   "metadata": {},
   "source": [
    "### LangChain Prompt Templates — Types + Practical Implementation\n",
    "\n",
    "#### ✅ PromptTemplate (Basic)\n",
    "\n",
    "> Basic prompt with string template\tused for General texts like generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06b808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following --> What is machine learning?.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"Question\"],\n",
    "    template=\"Answer the following --> {question}.\"\n",
    ")\n",
    "\n",
    "print(prompt.format(question=\"What is machine learning?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00e54e",
   "metadata": {},
   "source": [
    "#### ✅ FewShotPromptTemplate\n",
    "- In this technique internally the basic prompt templates are being used to craft multiple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751bfa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: fast\n",
      "Antonym: slow\n",
      "\n",
      "Word: hot\n",
      "Antonym:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"fast\", \"antonym\": \"slow\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=\"Word: {word}\\nAntonym: {antonym}\"\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Word: {input}\\nAntonym:\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format(input=\"hot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1aed7d",
   "metadata": {},
   "source": [
    "#### ✅ ChatPromptTemplate\n",
    "> Multi-message prompt formatting (system/user/assistant) used for Chat agents like ChatGPT, Gemini etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.\n",
      "Langchain is python framework for building applications with LLMs.\n",
      "What is LangChain?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"assistant\", \"Langchain is python framework for building applications with LLMs.\"),\n",
    "    (\"human\", \"What is LangChain?\")\n",
    "])\n",
    "\n",
    "formatted = chat_prompt.format_messages()\n",
    "for msg in formatted:\n",
    "    print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7f190",
   "metadata": {},
   "source": [
    "#### ✅ FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca2a0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1 + 1' additional_kwargs={} response_metadata={}\n",
      "content='2' additional_kwargs={} response_metadata={}\n",
      "content='5 * 3' additional_kwargs={} response_metadata={}\n",
      "content='15' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"1 + 1\", \"output\": \"2\"},\n",
    "    {\"input\": \"5 * 3\", \"output\": \"15\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "messages = prompt.format_messages(input=\"10 / 2\")\n",
    "for msg in messages:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c081d",
   "metadata": {},
   "source": [
    "#### ✅ System/Human/AI Message Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "806d5536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a travel guide.' additional_kwargs={} response_metadata={}\n",
      "content='Suggest a place to visit in India.' additional_kwargs={} response_metadata={}\n",
      "content='Visit Arunachalam in India!' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"You are a travel guide.\")\n",
    "human = HumanMessagePromptTemplate.from_template(\"Suggest a place to visit in {country}.\")\n",
    "ai = AIMessagePromptTemplate.from_template(\"Visit {destination} in {country}!\")\n",
    "\n",
    "print(system.format())\n",
    "print(human.format(country=\"India\"))\n",
    "print(ai.format(destination=\"Arunachalam\", country=\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e05af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76653c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a55d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
